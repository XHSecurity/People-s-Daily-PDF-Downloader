"""
äººæ°‘æ—¥æŠ¥PDFä¸‹è½½å·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰
ä¿®å¤å†…å®¹ï¼š
1. è§£å†³å¤šè¿›åº¦æ¡å®ä¾‹å†²çªé—®é¢˜
2. ä¼˜åŒ–æ‰¹é‡ä¸‹è½½è¿›åº¦æ˜¾ç¤º
3. å¢å¼ºå¼‚å¸¸å¤„ç†æœºåˆ¶
"""
import os
import re
import sys
import time
import shutil
import argparse
import logging
import datetime
from typing import Tuple, Optional, List

import requests
import PyPDF2
from rich.progress import (
    Progress,
    BarColumn,
    DownloadColumn,
    TextColumn,
    TimeRemainingColumn,
    TransferSpeedColumn,
    TaskID,
)
from rich.console import Console
from rich.logging import RichHandler

# åŸºç¡€ç›®å½•é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
os.makedirs(os.path.join(BASE_DIR, "logs"), exist_ok=True)

# å…¨å±€é…ç½®
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}
TIMEOUT = 15
MAX_RETRIES = 3

# åˆå§‹åŒ–æ§åˆ¶å°å’Œæ—¥å¿—
console = Console()
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        RichHandler(console=console, rich_tracebacks=True, show_path=False),
        logging.FileHandler(
            os.path.join(BASE_DIR, "logs/rmrb.log"),
            encoding="utf-8"
        ),
    ],
)
logger = logging.getLogger("RMZ_Downloader")


def init_environment() -> Tuple[str, str]:
    """åˆå§‹åŒ–ç¯å¢ƒå¹¶æ¸…ç†ä¸´æ—¶ç›®å½•"""
    download_dir = os.path.join(BASE_DIR, "download")
    temp_dir = os.path.join(BASE_DIR, "temp_part")

    for dir_path in [download_dir, temp_dir]:
        os.makedirs(dir_path, exist_ok=True)

    # æ¸…ç†ä¸´æ—¶ç›®å½•
    for f in os.listdir(temp_dir):
        file_path = os.path.join(temp_dir, f)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}")

    return temp_dir, download_dir


def validate_date(input_date: Optional[str]) -> str:
    """éªŒè¯å•ä¸ªæ—¥æœŸ"""
    today = datetime.date.today()

    if not input_date:
        return today.strftime("%Y-%m/%d")

    formats = [
        "%Y%m%d",  # YYYYMMDD
        "%Y-%m-%d",  # ISOæ ¼å¼
        "%Y/%m/%d",  # æ–œæ æ ¼å¼
        "%Y-%m/%d",  # ç›®æ ‡æ ¼å¼
        "%Y%m/%d",  # æ··åˆæ ¼å¼
    ]

    for fmt in formats:
        try:
            dt = datetime.datetime.strptime(input_date, fmt).date()
            if dt > today:
                raise ValueError("æ—¥æœŸä¸èƒ½è¶…è¿‡ä»Šå¤©")
            if dt.year < 2003:
                raise ValueError("ä»…æ”¯æŒ2003å¹´åŠä¹‹åçš„æŠ¥çº¸")
            return dt.strftime("%Y-%m/%d")
        except ValueError:
            continue

    logger.error(f"æ— æ•ˆæ—¥æœŸæ ¼å¼: {input_date} (æ”¯æŒæ ¼å¼: YYYYMMDD/YYYY-MM-DD/YYYY-MM/ddç­‰)")
    sys.exit(1)


def validate_date_range(range_str: str) -> List[datetime.date]:
    """éªŒè¯å¹¶è§£ææ—¥æœŸèŒƒå›´"""
    try:
        # ç»Ÿä¸€å»é™¤å¯èƒ½çš„åˆ†éš”ç¬¦
        clean_str = re.sub(r"[^0-9]", "", range_str)
        if len(clean_str) != 16:
            raise ValueError("æ— æ•ˆçš„æ—¥æœŸèŒƒå›´æ ¼å¼")

        # è§£æå¼€å§‹å’Œç»“æŸæ—¥æœŸ
        start_str = clean_str[:8]
        end_str = clean_str[8:]
        start_date = datetime.datetime.strptime(start_str, "%Y%m%d").date()
        end_date = datetime.datetime.strptime(end_str, "%Y%m%d").date()

        if start_date > end_date:
            raise ValueError("å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")

        if end_date > datetime.date.today():
            raise ValueError("ç»“æŸæ—¥æœŸä¸èƒ½è¶…è¿‡ä»Šå¤©")

        if start_date.year < 2003:
            raise ValueError("ä»…æ”¯æŒ2003å¹´åŠä¹‹åçš„æŠ¥çº¸")

        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        date_list = []
        current_date = start_date
        while current_date <= end_date:
            date_list.append(current_date)
            current_date += datetime.timedelta(days=1)

        return date_list
    except Exception as e:
        logger.error(f"æ—¥æœŸèŒƒå›´è§£æå¤±è´¥: {str(e)}")
        sys.exit(1)


def parse_date(target_date: str) -> Tuple[str, str, str]:
    """è§£ææ—¥æœŸä¸ºä¸åŒæ ¼å¼"""
    dt = datetime.datetime.strptime(target_date, "%Y-%m/%d")
    return (
        target_date,
        dt.strftime("%Y%m%d"),
        dt.strftime("%Y%m/%d")
    )


def safe_request(url: str) -> Optional[requests.Response]:
    """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚å‡½æ•°"""
    for _ in range(MAX_RETRIES):
        try:
            response = requests.get(
                url,
                headers=HEADERS,
                timeout=TIMEOUT,
                verify=False,
                allow_redirects=False
            )
            if response.status_code == 200:
                return response
            if response.status_code == 404:
                return None
        except Exception as e:
            logger.warning(f"è¯·æ±‚å¤±è´¥: {url} - {str(e)}")
            time.sleep(1)
    return None


def get_page_info(old_url: str, new_url: str) -> Tuple[int, bool]:
    """è·å–é¡µæ•°å¹¶åˆ¤æ–­ç‰ˆæœ¬"""
    # å°è¯•æ–°ç‰ˆç½‘ç«™
    if response := safe_request(new_url):
        if (pages := len(re.findall(r'pageLink', response.text))) > 0:
            return pages, True

    # å›é€€æ—§ç‰ˆç½‘ç«™
    if response := safe_request(old_url):
        return len(re.findall(r'nbs', response.text)), False

    logger.error("æ— æ³•è·å–æŠ¥çº¸ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ—¥æœŸ")
    sys.exit(1)


def download_pdf(url: str, filename: str, temp_dir: str,
                 progress: Progress, task_id: TaskID) -> bool:
    """å¸¦è¿›åº¦æ¡å’Œé‡è¯•çš„ä¸‹è½½å‡½æ•°"""
    for retry in range(MAX_RETRIES):
        try:
            response = requests.get(url, headers=HEADERS, stream=True, timeout=30)
            response.raise_for_status()

            # æ£€æŸ¥å†…å®¹ç±»å‹
            if 'application/pdf' not in response.headers.get('Content-Type', ''):
                logger.warning(f"éPDFå†…å®¹: {url}")
                return False

            total_size = int(response.headers.get('content-length', 0))
            file_path = os.path.join(temp_dir, filename)

            progress.update(task_id, total=total_size, visible=True)

            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024 * 1024):
                    if chunk:
                        f.write(chunk)
                        progress.update(task_id, advance=len(chunk))

            if os.path.getsize(file_path) >= 1024:  # è‡³å°‘1KB
                return True
        except Exception as e:
            logger.warning(f"ä¸‹è½½å¤±è´¥ ({retry + 1}/{MAX_RETRIES}): {filename} - {str(e)}")
            time.sleep(1)

    return False


def download_edition(target_date: str, temp_dir: str, output_dir: str,
                     progress: Optional[Progress] = None,
                     main_task: Optional[TaskID] = None) -> bool:
    """ä¸»ä¸‹è½½æµç¨‹ï¼ˆæ”¯æŒå¤–éƒ¨è¿›åº¦æ¡ï¼‰"""
    old_fmt, file_fmt, new_fmt = parse_date(target_date)
    output_path = os.path.join(output_dir, f"People's.Daily.{file_fmt}.pdf")

    if os.path.exists(output_path):
        logger.info(f"æ–‡ä»¶å·²å­˜åœ¨: {os.path.basename(output_path)}")
        return True

    # æ„é€ å°é¢URL
    old_cover = f"http://paper.people.com.cn/rmrb/html/{old_fmt}/nbs.D110000renmrb_01.htm"
    new_cover = f"http://paper.people.com.cn/rmrb/pc/layout/{new_fmt}/node_01.html"

    # è·å–é¡µæ•°å’Œç‰ˆæœ¬ä¿¡æ¯
    total_pages, is_new = get_page_info(old_cover, new_cover)
    logger.info(f"æ£€æµ‹åˆ°{target_date}å…±{total_pages}é¡µ ({'æ–°ç‰ˆ' if is_new else 'æ—§ç‰ˆ'})")

    # è¿›åº¦æ¡ç®¡ç†
    local_progress = progress or Progress(
        TextColumn("[bold blue]{task.fields[filename]}", justify="right"),
        BarColumn(bar_width=None),
        "[progress.percentage]{task.percentage:>3.1f}%",
        "â€¢",
        DownloadColumn(),
        "â€¢",
        TransferSpeedColumn(),
        "â€¢",
        TimeRemainingColumn(),
        console=console,
    )
    use_local_progress = not progress

    success = 0
    task_id = TaskID(-1)

    try:
        if use_local_progress:
            local_progress.start()

        # æ·»åŠ ä¸‹è½½ä»»åŠ¡
        task_id = local_progress.add_task(
            "downloading",
            filename=f"{target_date} åˆå§‹åŒ–...",
            total=0,
            visible=True
        )

        # æ›´æ–°ä¸»ä»»åŠ¡æè¿°
        if main_task and progress:
            progress.update(
                main_task,
                description=f"[cyan]ä¸‹è½½ {target_date}",
                refresh=True
            )

        for page in range(1, total_pages + 1):
            # æ£€æŸ¥ç”¨æˆ·ä¸­æ–­
            if main_task and progress and progress.tasks[main_task].finished:
                raise KeyboardInterrupt()

            filename = f"rmrb{file_fmt}{page:02d}.pdf"
            local_progress.update(
                task_id,
                filename=f"{target_date} ç¬¬{page:02d}é¡µ",
                refresh=True
            )

            # æ„é€ ä¸‹è½½é“¾æ¥
            if is_new:
                node_url = f"http://paper.people.com.cn/rmrb/pc/layout/{new_fmt}/node_{page:02d}.html"
                if not (response := safe_request(node_url)):
                    continue
                if pdf_matches := re.findall(r'(/attachement.*?\.pdf)', response.text):
                    url = f"http://paper.people.com.cn/rmrb/pc/{pdf_matches[0]}"
                else:
                    logger.error(f"ç¬¬{page}é¡µé“¾æ¥æœªæ‰¾åˆ°")
                    continue
            else:
                url = f"http://paper.people.com.cn/rmrb/images/{old_fmt}/rmrb{file_fmt}{page:02d}.pdf"

            if download_pdf(url, filename, temp_dir, local_progress, task_id):
                success += 1

        if success < total_pages:
            logger.warning(f"æˆåŠŸä¸‹è½½{success}/{total_pages}é¡µ")
            return False
        return True

    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ç»ˆæ­¢ä¸‹è½½")
        return False
    except Exception as e:
        logger.error(f"ä¸‹è½½å¼‚å¸¸: {str(e)}")
        return False
    finally:
        local_progress.remove_task(task_id)
        if use_local_progress:
            local_progress.stop()


def merge_pdfs(temp_dir: str, output_dir: str):
    """åˆå¹¶PDFå¹¶æ ¡éªŒå®Œæ•´æ€§"""
    try:
        pdf_files = sorted(
            [f for f in os.listdir(temp_dir) if f.endswith(".pdf")],
            key=lambda x: int(x[-6:-4])
        )

        if not pdf_files:
            logger.error("æ²¡æœ‰æ‰¾åˆ°å¯åˆå¹¶çš„æ–‡ä»¶")
            return False

        merger = PyPDF2.PdfMerger()
        valid_files = []
        for f in pdf_files:
            path = os.path.join(temp_dir, f)
            if os.path.getsize(path) < 1024:
                logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡ä»¶: {f}")
                continue
            try:
                merger.append(path)
                valid_files.append(f)
            except PyPDF2.errors.PdfReadError:
                logger.error(f"æ–‡ä»¶æŸå: {f}")
                return False

        if len(valid_files) == 0:
            logger.error("æ²¡æœ‰æœ‰æ•ˆçš„PDFæ–‡ä»¶å¯ä¾›åˆå¹¶")
            return False

        output_name = f"People's.Daily.{valid_files[0][4:12]}.pdf"
        output_path = os.path.join(output_dir, output_name)
        merger.write(output_path)
        merger.close()
        logger.info(f"åˆå¹¶æˆåŠŸ: {output_path}")
        return True
    except Exception as e:
        logger.critical(f"åˆå¹¶å¤±è´¥: {str(e)}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="äººæ°‘æ—¥æŠ¥PDFä¸‹è½½å·¥å…·",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "-d", "--date",
        type=str,
        help="æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYYMMDD/YYYY-MM-DD/YYYY-MM/dd)"
    )
    parser.add_argument(
        "-r", "--range",
        type=str,
        help="æ—¥æœŸèŒƒå›´ (æ ¼å¼: YYYYMMDD-YYYYMMDD æˆ– YYYY-MM-DD-YYYY-MM-DD)"
    )
    args = parser.parse_args()

    # å‚æ•°æ£€æŸ¥
    if args.date and args.range:
        logger.error("ä¸èƒ½åŒæ—¶ä½¿ç”¨ -d å’Œ -r å‚æ•°")
        sys.exit(1)
    if not args.date and not args.range:
        logger.error("å¿…é¡»æŒ‡å®šæ—¥æœŸå‚æ•° (-d) æˆ–æ—¥æœŸèŒƒå›´å‚æ•° (-r)")
        sys.exit(1)

    temp_dir, output_dir = init_environment()
    console.rule("[bold cyan]äººæ°‘æ—¥æŠ¥PDFä¸‹è½½å·¥å…·[/bold cyan]")
    console.print(f"ç‰ˆæœ¬: 2025.4 (ä¿®å¤ç‰ˆ)", style="bold yellow")

    try:
        if args.range:
            date_list = validate_date_range(args.range)
            total_days = len(date_list)
            logger.info(f"å‡†å¤‡ä¸‹è½½ {total_days} å¤©çš„æŠ¥çº¸")

            with Progress(
                    TextColumn("[bold cyan]{task.description}"),
                    BarColumn(bar_width=None),
                    "[progress.percentage]{task.percentage:>3.0f}%",
                    "â€¢",
                    TimeRemainingColumn(),
                    console=console,
                    refresh_per_second=10
            ) as main_progress:
                main_task = main_progress.add_task(
                    "æ‰¹é‡ä¸‹è½½è¿›åº¦",
                    total=total_days,
                    visible=True
                )

                for idx, date_obj in enumerate(date_list, 1):
                    current_date = date_obj.strftime("%Y-%m-%d")
                    target_date = date_obj.strftime("%Y-%m/%d")

                    # æ›´æ–°ä¸»è¿›åº¦æ¡
                    main_progress.update(
                        main_task,
                        description=f"å¤„ç† {current_date} ({idx}/{total_days})",
                        advance=1,
                        refresh=True
                    )

                    try:
                        current_temp_dir, _ = init_environment()

                        # æ‰§è¡Œä¸‹è½½
                        download_success = download_edition(
                            target_date,
                            current_temp_dir,
                            output_dir,
                            progress=main_progress,
                            main_task=main_task
                        )

                        # åˆå¹¶PDF
                        if download_success:
                            merge_success = merge_pdfs(current_temp_dir, output_dir)
                            if not merge_success:
                                logger.error(f"{current_date} åˆå¹¶å¤±è´¥")
                        else:
                            logger.warning(f"{current_date} ä¸‹è½½æœªå®Œæˆ")

                    except Exception as e:
                        logger.error(f"{current_date} å¤„ç†å¤±è´¥: {str(e)}")
                    finally:
                        shutil.rmtree(current_temp_dir, ignore_errors=True)

            logger.info("ğŸ‰ æ‰¹é‡ä¸‹è½½å®Œæˆï¼")

        else:
            target_date = validate_date(args.date)
            logger.info(f"ç›®æ ‡æ—¥æœŸ: {target_date}")
            download_success = download_edition(target_date, temp_dir, output_dir)
            if download_success:
                merge_success = merge_pdfs(temp_dir, output_dir)
                if not merge_success:
                    logger.error("åˆå¹¶å¤±è´¥")
            shutil.rmtree(temp_dir, ignore_errors=True)
            logger.info("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")

    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ç»ˆæ­¢æ“ä½œ")
        sys.exit(130)
    except Exception as e:
        logger.critical(f"ç¨‹åºå¼‚å¸¸: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()